{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LAB1_DEEPLEARNING\n",
        "- Find datasets here - [link](https://drive.google.com/drive/folders/1FvSShuY_8QxPmsrHvuSkFYYc5ZBNbetU?usp=sharing)\n",
        "- download the dataset and change the path n run "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G-_qBczZ6NXv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AER39TQ7F7X",
        "outputId": "ca1aa52b-d4a5-4d27-b2eb-0d5f3981dff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: images\n",
            "Dataset: labels\n",
            "Dataset: images\n",
            "Dataset: labels\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "\n",
        "def inspect_h5file(file_path):\n",
        "    with h5py.File(file_path, \"r\") as file:\n",
        "        def printname(name, obj):\n",
        "            if isinstance(obj, h5py.Dataset):\n",
        "                print(f\"Dataset: {name}\")\n",
        "            elif isinstance(obj, h5py.Group):\n",
        "                print(f\"Group: {name}\")\n",
        "\n",
        "        file.visititems(printname)\n",
        "\n",
        "inspect_h5file('/content/drive/MyDrive/data-set-sem5/lab1/Train.h5')\n",
        "inspect_h5file('/content/drive/MyDrive/data-set-sem5/lab1/Test.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lvsIR3bD7Nwp"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    train_dataset = h5py.File('/content/drive/MyDrive/data-set-sem5/lab1/Train.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"images\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"labels\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('/content/drive/MyDrive/data-set-sem5/lab1/Test.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"images\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"labels\"][:]) # your test set labels\n",
        "\n",
        "    # classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "\n",
        "    # train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    # test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xkfgphtz7adh"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(dim, num_classes):\n",
        "    w = np.zeros((dim, num_classes))\n",
        "    b = np.zeros((num_classes))\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lDx-MWQf7l2X"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MR9SFFh47ogn"
      },
      "outputs": [],
      "source": [
        "def compute_cost_grads(w, b, X, Y):\n",
        "    m = X.shape[1]\n",
        "    z = np.dot(w.T, X) + b[:, np.newaxis]\n",
        "    A = softmax(z)\n",
        "\n",
        "    cost = -np.sum(Y * np.log(A + 1e-8)) / m\n",
        "\n",
        "    dz = A - Y\n",
        "    dw = np.dot(X, dz.T) / m\n",
        "    db = np.sum(dz, axis=1) / m\n",
        "\n",
        "    grads = {\"dw\": dw, \"db\": db}\n",
        "\n",
        "    return grads, cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "utkLT5277rth"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(labels, num_classes):\n",
        "    return np.eye(num_classes)[labels.reshape(-1)].T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Guc9ZVdv7urc"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X, Y, num_classes, learning_rate, num_iterations):\n",
        "    dim = X.shape[0]\n",
        "    w, b = initialize_parameters(dim, num_classes)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        grads, cost = compute_cost_grads(w, b, X, Y)\n",
        "\n",
        "        w -= learning_rate * grads['dw']\n",
        "        b -= learning_rate * grads['db']\n",
        "\n",
        "        # Implement learning rate decay\n",
        "        learning_rate *= 0.99\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}: Cost {cost}\")\n",
        "\n",
        "    return w, b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nIox7rVX7xDM"
      },
      "outputs": [],
      "source": [
        "def predict(w, b, X):\n",
        "    z = np.dot(w.T, X) + b[:, np.newaxis]\n",
        "    A = softmax(z)\n",
        "    return np.argmax(A, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PoLg-SOSCvel"
      },
      "outputs": [],
      "source": [
        "# Implement the multilayer model function\n",
        "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
        "    \"\"\"\n",
        "    Builds the logistic regression model by calling the function you've implemented previously.\n",
        "\n",
        "    Arguments:\n",
        "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
        "    Y_train -- training labels represented by a numpy array (one-hot vector) of shape (number of classes, m_train)\n",
        "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
        "    Y_test -- test labels represented by a numpy array (one-hot vector) of shape (number of classes, m_test)\n",
        "    num_iterations -- number of iterations to optimize the parameters\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "    print_cost -- if set to True, this will print the cost every 100 iterations\n",
        "\n",
        "    Returns:\n",
        "    d -- dictionary containing information about the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize parameters with zeros\n",
        "    dim, num_classes = X_train.shape[0], Y_train.shape[0]\n",
        "    w, b = initialize_parameters(dim, num_classes)\n",
        "\n",
        "    # Gradient descent optimization\n",
        "    parameters = gradient_descent(X_train, Y_train, num_classes, learning_rate, num_iterations)\n",
        "\n",
        "    w, b = parameters\n",
        "\n",
        "    # Predict test/train set examples\n",
        "    Y_prediction_train = predict(w, b, X_train)\n",
        "    Y_prediction_test = predict(w, b, X_test)\n",
        "\n",
        "    # Print train/test Errors\n",
        "    train_accuracy = np.mean(Y_prediction_train == np.argmax(Y_train, axis=0))\n",
        "    test_accuracy = np.mean(Y_prediction_test == np.argmax(Y_test, axis=0))\n",
        "\n",
        "    print(f\"Train Accuracy: {train_accuracy * 100}%\")\n",
        "    print(f\"Test Accuracy: {test_accuracy * 100}%\")\n",
        "\n",
        "    d = {\"train_accuracy\": train_accuracy,\n",
        "         \"test_accuracy\": test_accuracy,\n",
        "         \"w\": w,\n",
        "         \"b\": b,\n",
        "         \"learning_rate\": learning_rate,\n",
        "         \"num_iterations\": num_iterations}\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "G0T1lEsx7zRZ"
      },
      "outputs": [],
      "source": [
        "train_images, train_labels, test_images, test_labels = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "98A7Mgl_76Ad"
      },
      "outputs": [],
      "source": [
        "train_images_flat = train_images.reshape(train_images.shape[0], -1).T / 255.0\n",
        "test_images_flat = test_images.reshape(test_images.shape[0], -1).T / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9dDIL8e-8AP9"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "train_labels_one_hot = one_hot_encode(train_labels, num_classes)\n",
        "test_labels_one_hot = one_hot_encode(test_labels, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nV42UzkDDkR",
        "outputId": "d747646c-8e56-49ec-e607-83f77bf07e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0: Cost 1.6094378624341021\n",
            "Iteration 100: Cost 2.0608597757910463\n",
            "Iteration 200: Cost 1.0741010088695873\n",
            "Iteration 300: Cost 1.0576980935565206\n",
            "Iteration 400: Cost 1.0523962696329634\n",
            "Iteration 500: Cost 1.0505254441199157\n",
            "Iteration 600: Cost 1.0498492118618397\n",
            "Iteration 700: Cost 1.0496027994957164\n",
            "Iteration 800: Cost 1.0495127517340392\n",
            "Iteration 900: Cost 1.049479810974048\n",
            "Iteration 1000: Cost 1.049467756217077\n",
            "Iteration 1100: Cost 1.0494633441378707\n",
            "Iteration 1200: Cost 1.0494617292213013\n",
            "Iteration 1300: Cost 1.0494611381159205\n",
            "Iteration 1400: Cost 1.0494609217530795\n",
            "Iteration 1500: Cost 1.0494608425573957\n",
            "Iteration 1600: Cost 1.0494608135692292\n",
            "Iteration 1700: Cost 1.0494608029586248\n",
            "Iteration 1800: Cost 1.0494607990748008\n",
            "Iteration 1900: Cost 1.0494607976531953\n",
            "Iteration 2000: Cost 1.0494607971328418\n",
            "Iteration 2100: Cost 1.0494607969423757\n",
            "Iteration 2200: Cost 1.049460796872659\n",
            "Iteration 2300: Cost 1.0494607968471406\n",
            "Iteration 2400: Cost 1.0494607968377998\n",
            "Iteration 2500: Cost 1.0494607968343808\n",
            "Iteration 2600: Cost 1.0494607968331293\n",
            "Iteration 2700: Cost 1.0494607968326712\n",
            "Iteration 2800: Cost 1.0494607968325036\n",
            "Iteration 2900: Cost 1.0494607968324423\n",
            "Train Accuracy: 59.29169840060929%\n",
            "Test Accuracy: 50.83333333333333%\n"
          ]
        }
      ],
      "source": [
        "d = model(train_images_flat, train_labels_one_hot, test_images_flat, test_labels_one_hot, num_iterations=3000, learning_rate=0.006, print_cost=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
